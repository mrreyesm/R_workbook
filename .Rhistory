library(tidyverse) # just import it
library(haven) #to play with SPSS files
library(epiDisplay) #nice frequency tables
library(Hmisc) # useful for data analysis rcorr
library(pastecs) #desc statistics
options(scipen=100) #options to alter desc stats in pastecs
options(digits=3) #options to alter desc stats in pastecs
library(nortest) #Anderson-Darling normality test
library(moments) #skewness
library(reshape2) #transform data
library(qqplotr) #qqplots
library(ggpubr)  #more fancy graphs
library(xlsx) #excel
library(janitor) #adds a total sum row
library(corrplot) #correlation plots
library(rstatix) #cramer's V
library(foreign) #mport data file
library(fBasics) # Basic Statistics
library(lmtest) #dwtest
outlier_flag_3s<-function(x)
{
hist(x)
summary(x)
# using here the z values
flag<- ifelse(test = scale(x) > 3 | scale(x)< -3, yes = 1, no = 0)
# number of outlier
table(flag)
# return the vector representing the flag variable
flag
}
outlier_flag_2s<-function(x)
{
hist(x)
summary(x)
# using here the z values
flag<- ifelse(test = scale(x) > 2 | scale(x)< -2, yes = 1, no = 0)
# number of outlier
table(flag)
# return the vector representing the flag variable
flag
}
outlier_flag_1s<-function(x)
{
hist(x)
summary(x)
# using here the z values
flag<- ifelse(test = scale(x) > 1 | scale(x)< -1, yes = 1, no = 0)
# number of outlier
table(flag)
# return the vector representing the flag variable
flag
}
#recommended application
#x: dataframe
#y: variable
#n: # of standard deviations
#x$y_nsflag<-outlier_flag_ns(x$y) #add flag variable to the dataframe
#head(x)#view new column within the df (optional)
#table(x$y_nsflag) #counts how many variables are outliers and how many not
#length(x$y) #count of rows with outliers
#length(x$y[x$y_nsflag==0]) #count of rows without outliers
#--------------------------------------------------->SIMPLE FUNCTION TO GET MODE
getmode <- function(v)
{
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#just pass the vector or variable inside
#--------------------------------------------------->DESSCRIBE VARIABLE FUNCTION
describeme <- function(v, breaks = 5, norm = FALSE)
{ #-------------------3S RULE---------------------------------------------------
#normal distribution 68.27 1s, 95.45 within 2s and 99.73 within 3s
#unimodal symetric distribution 55.56 1s, 88.90 within 2s and 95.06 within 3s
#distribution of any shape 0 1s, 75 within 2s and 88.89 within 3s
up_2s <- mean(v, na.rm= TRUE)+2*sd(v, na.rm= TRUE)
lo_2s <- mean(v, na.rm= TRUE)-2*sd(v, na.rm= TRUE)
up_3s <- mean(v, na.rm= TRUE)+3*sd(v, na.rm= TRUE)
lo_3s <- mean(v, na.rm= TRUE)-3*sd(v, na.rm= TRUE)
print(stat.desc(v,basic=TRUE, desc=TRUE,norm = norm, p=0.95))
cat("\n")
print(paste("Influentia values: At least 90-95% of the values lie between ",
signif(lo_2s,4), " and ", signif(up_2s,4)))
print(paste("95-99% or more of the values lie between ",signif(lo_3s,4),
" and ", signif(up_3s,4)))
cat("\n")
print("Outliers for 2s Rule")
print("0 = Within 2s, 1 = Outlier")
flag<- ifelse(test = scale(v) > 2 | scale(v)< -2, yes = 1, no = 0)
print(table(flag))
cat("\n")
print("Outliers for 3s Rule")
print("0 = Within 3s, 1 = Outlier")
flag<- ifelse(test = scale(v) > 3 | scale(v)< -3, yes = 1, no = 0)
print(table(flag))
n <- length(v)
min <- min(v)
max <- max(v)
m<-mean(v, na.rm = TRUE)
med <- median(v, na.rm = TRUE)
std<-sqrt(var(v, na.rm = TRUE))
#varaince-squared sum of the deviation of the values of the mean
hist(v, density=20, breaks=breaks, prob=TRUE,
xlab="Variable",
main="normal curve over histogram")
curve(dnorm(x, mean=m, sd=std),
col="darkblue", add=TRUE)
legend("topright", legend = c(paste("Mean: ",signif(m,5)),
paste("Median: ",signif(med,5)),
paste("Min: ",signif(min,5)),
paste("Max: ",signif(max,5)),
paste("Std Dev: ",signif(std,5)),
paste("n: ",signif(n,5))),
title = "Descriptive Stats", title.adj = 0.75,
lty = 1, lwd = 2, box.lty = 0, bg="transparent")
}
employee <- read_sav("employee_survey.sav")# used for examples
dice <- read_sav("perfect_dice.sav")
#### import Excel files
job <- read.xlsx("job_profile_examples.xlsx", sheetIndex = 1)# used for examples
#### Import CSVs with german decimal marks
healthy <- read_delim("healthy_breakfast_cereals.txt", delim = "\t",
locale = locale(decimal_mark = ","))
employee  <- employee  %>% mutate(gender_lbl = as_factor(gender))
employee  <- employee  %>% mutate(motivation_lbl = as_factor(motivation))
job$gender_dic <- ifelse(job$gender == "m", 1, 0)
x$y <- ifelse(x$y == -1, NA, x$y)
#replace missing values (-1) & transform factor into character for numeric lbls
x$y_label <- ifelse(x$y_label == "-1", NA,as.character(x$y_label))
#Other ecoding and NA identification
x <- x %>% mutate(z = case_when(is.na(y) ~ NA_real_, y=="X" ~ 1  ))
x <- x %>% mutate(y = case_when(is.na(z ) ~ "NA"  , z == 1  ~ "X"))
x$y <- ifelse(x$y == "NA", NA, x$y)
#Most effective for many variables in conjunction with unique
job$type_job_rec <- recode(job$type, "Team Manager"=1,
"Office Worker"=2,
"blue-collar Worker"=3,
"unskilled Worker"=4,
"Trainee"=5)
unique(job$type_job)
#Number of distinct values in a column
length(unique(job[["type_job"]]))
y_thresholds<-c(3,5,7,10)
y_labels<-c('3-5','6-7','8-10')
x$y_categories<-cut(x$y,breaks=y_thresholds,labels=y_labels,right=T)
salary.thresholds<-c(0,1500,2500,4000)
salary.labels<-c('low','middle','high')
employee_survey$salary.categories<-cut(employee_survey$salary,
breaks=salary.thresholds,
labels=salary.labels,right=T)
job %>% group_by(gender) %>% summarise(mean(salary),
median(salary),
getmode(salary))
tab1(job$type_job, cum.percent = TRUE,horiz=FALSE, main='Distrib of variable Y')
library(tidyverse) # just import it
library(haven) #to play with SPSS files
library(epiDisplay) #nice frequency tables
library(Hmisc) # useful for data analysis rcorr
library(pastecs) #desc statistics
options(scipen=100) #options to alter desc stats in pastecs
options(digits=3) #options to alter desc stats in pastecs
library(nortest) #Anderson-Darling normality test
library(moments) #skewness
library(reshape2) #transform data
library(qqplotr) #qqplots
library(ggpubr)  #more fancy graphs
library(xlsx) #excel
library(janitor) #adds a total sum row
library(corrplot) #correlation plots
library(rstatix) #cramer's V
library(foreign) #mport data file
library(fBasics) # Basic Statistics
library(lmtest) #dwtest
outlier_flag_3s<-function(x)
{
hist(x)
summary(x)
# using here the z values
flag<- ifelse(test = scale(x) > 3 | scale(x)< -3, yes = 1, no = 0)
# number of outlier
table(flag)
# return the vector representing the flag variable
flag
}
outlier_flag_2s<-function(x)
{
hist(x)
summary(x)
# using here the z values
flag<- ifelse(test = scale(x) > 2 | scale(x)< -2, yes = 1, no = 0)
# number of outlier
table(flag)
# return the vector representing the flag variable
flag
}
outlier_flag_1s<-function(x)
{
hist(x)
summary(x)
# using here the z values
flag<- ifelse(test = scale(x) > 1 | scale(x)< -1, yes = 1, no = 0)
# number of outlier
table(flag)
# return the vector representing the flag variable
flag
}
#recommended application
#x: dataframe
#y: variable
#n: # of standard deviations
#x$y_nsflag<-outlier_flag_ns(x$y) #add flag variable to the dataframe
#head(x)#view new column within the df (optional)
#table(x$y_nsflag) #counts how many variables are outliers and how many not
#length(x$y) #count of rows with outliers
#length(x$y[x$y_nsflag==0]) #count of rows without outliers
#--------------------------------------------------->SIMPLE FUNCTION TO GET MODE
getmode <- function(v)
{
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
#just pass the vector or variable inside
#--------------------------------------------------->DESSCRIBE VARIABLE FUNCTION
describeme <- function(v, breaks = 5, norm = FALSE)
{ #-------------------3S RULE---------------------------------------------------
#normal distribution 68.27 1s, 95.45 within 2s and 99.73 within 3s
#unimodal symetric distribution 55.56 1s, 88.90 within 2s and 95.06 within 3s
#distribution of any shape 0 1s, 75 within 2s and 88.89 within 3s
up_2s <- mean(v, na.rm= TRUE)+2*sd(v, na.rm= TRUE)
lo_2s <- mean(v, na.rm= TRUE)-2*sd(v, na.rm= TRUE)
up_3s <- mean(v, na.rm= TRUE)+3*sd(v, na.rm= TRUE)
lo_3s <- mean(v, na.rm= TRUE)-3*sd(v, na.rm= TRUE)
print(stat.desc(v,basic=TRUE, desc=TRUE,norm = norm, p=0.95))
cat("\n")
print(paste("Influentia values: At least 90-95% of the values lie between ",
signif(lo_2s,4), " and ", signif(up_2s,4)))
print(paste("95-99% or more of the values lie between ",signif(lo_3s,4),
" and ", signif(up_3s,4)))
cat("\n")
print("Outliers for 2s Rule")
print("0 = Within 2s, 1 = Outlier")
flag<- ifelse(test = scale(v) > 2 | scale(v)< -2, yes = 1, no = 0)
print(table(flag))
cat("\n")
print("Outliers for 3s Rule")
print("0 = Within 3s, 1 = Outlier")
flag<- ifelse(test = scale(v) > 3 | scale(v)< -3, yes = 1, no = 0)
print(table(flag))
n <- length(v)
min <- min(v)
max <- max(v)
m<-mean(v, na.rm = TRUE)
med <- median(v, na.rm = TRUE)
std<-sqrt(var(v, na.rm = TRUE))
#varaince-squared sum of the deviation of the values of the mean
hist(v, density=20, breaks=breaks, prob=TRUE,
xlab="Variable",
main="normal curve over histogram")
curve(dnorm(x, mean=m, sd=std),
col="darkblue", add=TRUE)
legend("topright", legend = c(paste("Mean: ",signif(m,5)),
paste("Median: ",signif(med,5)),
paste("Min: ",signif(min,5)),
paste("Max: ",signif(max,5)),
paste("Std Dev: ",signif(std,5)),
paste("n: ",signif(n,5))),
title = "Descriptive Stats", title.adj = 0.75,
lty = 1, lwd = 2, box.lty = 0, bg="transparent")
}
employee <- read_sav("employee_survey.sav")# used for examples
dice <- read_sav("perfect_dice.sav")
#### import Excel files
job <- read.xlsx("job_profile_examples.xlsx", sheetIndex = 1)# used for examples
#### Import CSVs with german decimal marks
healthy <- read_delim("healthy_breakfast_cereals.txt", delim = "\t",
locale = locale(decimal_mark = ","))# used for examples
#using SPSS labels as another column
employee  <- employee  %>% mutate(gender_lbl = as_factor(gender))
employee  <- employee  %>% mutate(motivation_lbl = as_factor(motivation))
#view df in another window
job$gender_dic <- ifelse(job$gender == "m", 1, 0)
x$y <- ifelse(x$y == -1, NA, x$y)
#replace missing values (-1) & transform factor into character for numeric lbls
x$y_label <- ifelse(x$y_label == "-1", NA,as.character(x$y_label))
#Other ecoding and NA identification
x <- x %>% mutate(z = case_when(is.na(y) ~ NA_real_, y=="X" ~ 1  ))
x <- x %>% mutate(y = case_when(is.na(z ) ~ "NA"  , z == 1  ~ "X"))
x$y <- ifelse(x$y == "NA", NA, x$y)
#Most effective for many variables in conjunction with unique
job$type_job_rec <- recode(job$type, "Team Manager"=1,
"Office Worker"=2,
"blue-collar Worker"=3,
"unskilled Worker"=4,
"Trainee"=5)
#get uniquevalues of columns
unique(job$type_job)
#Number of distinct values in a column
length(unique(job[["type_job"]]))
#binning and determine categories
#from 3 to 5, from 6 to 7, and from 8 to 10. Use with min and max functions!
y_thresholds<-c(3,5,7,10)
y_labels<-c('3-5','6-7','8-10')
x$y_categories<-cut(x$y,breaks=y_thresholds,labels=y_labels,right=T)
salary.thresholds<-c(0,1500,2500,4000)
salary.labels<-c('low','middle','high')
employee_survey$salary.categories<-cut(employee_survey$salary,
breaks=salary.thresholds,
labels=salary.labels,right=T)
job %>% group_by(gender) %>% summarise(mean(salary),
median(salary),
getmode(salary))
tab1(job$type_job, cum.percent = TRUE,horiz=FALSE, main='Distrib of variable Y')
boxplot(job$salary)
histogram(job$salary
)
describeme(job$salary, breaks = 10, norm = TRUE)
job$salary_2sflag<-outlier_flag_2s(job$salary) #add flag variable to the dframe
head(job)#view new column within the df (optional)
table(job$salary_2sflag)#counts how many variables are outliers and how many not
length(job$salary) #count of rows with outliers (optional)
length(job$salary[job$salary_2sflag==0]) #count of rows without outliers (opt)
# Create Z score variable and gives you % of observations within n Sts dvs
# zscore = (variable - mean)/stdev same as scale
job <- job %>% mutate(salary_z = scale(salary))
paste((job %>% dplyr::filter(salary_z > -2 & salary_z < 2) %>%
nrow())/(job %>% nrow())*100,"% of Salaries are inside the 2s rule")
describeme(job$salary[job$salary_2sflag==0], breaks = 10, norm = TRUE)
#create another df without the outliers, don't overwrite
#----------------------------------------------Assessing behaviour of a variable
describeme(job$salary, breaks = 10, norm = TRUE)
sales <- read_sav("sales.sav")
res2 <- rcorr(as.matrix(sales), type = c("pearson","spearman"))
res2$r
# Extract p-values
res2$P
corrplot(cor(sales), type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
corrplot(cor(sales),method = "number",type = "upper") #show only upper side
describeme(sales$price)
describeme(sales$sales)
# for an appropriate regres
lm_x <- lm( sales ~ price, sales)
summary(lm_x)
anova(lm_x)
lm_x$coefficients
ggplot(sales, aes(x = price, y = sales)) +
geom_point(alpha = 0.75) +
geom_smooth(method="lm", color = 'red')
ggplot(sales, aes(x = price, y = sales)) +
geom_point(alpha=0.7) +                           # observed data
geom_point(aes(x = price, y = lm_x$fitted.values),  # predicted data
color='red', alpha=0.5) +
geom_segment(aes(xend = price, yend = lm_x$fitted.values),
color='red', linetype='dashed', alpha=0.25)
ggplot(sales, aes(x = price, y = sales)) +
geom_point(alpha=0.7) +
geom_abline(slope = lm_x$coefficients[[2]],
intercept = lm_x$coefficients[[1]],
color='red', alpha=0.5)
ggplot(sales, aes(x = price, y = sales)) +
geom_point(alpha=0.7) +
geom_abline(slope = lm_x$coefficients[[2]],
intercept = lm_x$coefficients[[1]],
color='red', alpha=0.5)
ggplot(sales, aes(x = price, y = sales)) +
geom_point(alpha=0.7) +                           # observed data
geom_point(aes(x = price, y = lm_x$fitted.values),  # predicted data
color='red', alpha=0.5) +
geom_segment(aes(xend = price, yend = lm_x$fitted.values),
color='red', linetype='dashed', alpha=0.25)
varsk %>%
ggplot( aes(x=Date, y=PxLast)) +
scale_x_date(date_breaks = "6 month", date_labels = "%b %Y")+
geom_line( color="grey") +
geom_point(shape=21, color="black", fill="#69b3a2") +
ggtitle("Evolution of Price Shares")+
theme(axis.text.x=element_text(angle=60, hjust=1))
